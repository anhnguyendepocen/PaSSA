---
title: "Power and Sample Size Analysis"
author: "Clay Ford"
date: Spring 2016
output: beamer_presentation
---

## Topics

- Quick intro to power and sample size concepts as they relate to hypothesis testing
- Calculate power and sample size for various statistical tests using the `pwr` package in `R` and a few built-in `R` functions


## What is power?

Power is the probability a statistical test will detect a hypothesized effect.  
\ 

In a hypothesis test, we assume one of two things true:

1. Null Hypothesis: No effect
2. Alternative Hypothesis: _some_ effect

We would like to design an experiment such we have a high probability (or high power) of rejecting #1 if #2 is true. The usual desired power is at least 0.80, or 80%.

## Working Toy Example

I suspect most people place name tags on the left side of their chest (probably because most people are right handed). I create an experiment to test this hunch. I randomly sample $n$ people and count the number of people, $X$, who place a name tag on the left. If $X$ exceeds some number, I'll conclude I'm correct. I want my experiment to have a high probability (power) of verifying this hunch if it's true.  
\ 

I can calculate power for a given sample size, or I can calculate sample size for a given power.

## Calculating power or sample size

To calculate power or sample size for my name tag experiment, I have to make certain assumptions and decisions:

- Decide which statistical test to use (_one-sample proportion test_)
- For power, I have to set sample size; for sample size, I have to set the desired power
- Decide on _effect size_, the probability of placing tag on left assuming my hypothesis is correct
- Determine the number of tags on left that convince me the hypothesis is true (_critical region_), or set a p-value cutoff such as 0.05 (_significance level_)
- Decide if my test is "one-sided" (greater or less than null) or "two-sided" (different from null)


## It's all in your head

Calculating power and sample size is just a thought experiment based on assumed values and a hypothetical scenario.

Does that make it useless? No! It makes you plan your experiment.

- Decide what makes for a meaningful effect
- Determine which statistical test you're going to use to detect the effect
- Approximate a suitable sample size
- Or approximate power of experiment if you have a limited sample


## One possible experiment

Let $X$ equal number of tags placed on left and assume $X$ has binomial distribution. Conclude people prefer left if I observe $X > 14$ "lefts" in 20 trials.  
\ 

The binomial distribution can be thought of as the "coin-flipping" distribution. If I flip 20 coins each with the same probability of heads, I will get 0 - 20 heads. Some results, such as 10 or 11, are more likely to occur than other results, such as 0 or 20.  
\ 

The binomial distribution assigns probabilities to those results based on two parameters: _n_, the number of flips (or trials), and _p_, the probability of heads (or success).

## The binomial distribution

```{r echo=FALSE}

qs <- 0:20
plot(qs, dbinom(x = qs, size = 20, prob = 0.5), type="h", xlab="X", ylab="P(X)",
     main="Binomial distribution with n=20 and p=0.5")

```

## One possible experiment - cont'd

Let $X$ equal number of tags placed on left and assume $X$ has binomial distribution. Conclude people prefer left if I observe $X > 14$ "lefts" in 20 trials.  
\ 

Why 14? Less than 5% chance that would happen if people have no preference.  
\ 

$P(X > 14 | n = 20, p = 0.50) < 0.05$  
\ 

To determine in R:
```{r}
qbinom(p = 0.05, size = 20, prob = 0.5, lower.tail = F)
```

## $P(X) > 14$

```{r echo=FALSE}

qs <- 0:20
plot(qs, dbinom(x = qs, size = 20, prob = 0.5), type="h", xlab="X", ylab="P(X)",
     main="Binomial distribution with n=20 and p=0.5")
segments(x0 = 15:20, y0 = 0, x1 = 15:20, y1 = dbinom(x = 15:20, size = 20, prob = 0.5),col = "red", lwd = 3)
text(x = 17, y = .05, labels = expression(P(X) > 14 %~~% 0.02))

```



## One possible experiment - cont'd

Assume people prefer left 60% of the time and that $X$ has binomial distribution. Let's say I sample 20 people.  
\ 

Power is $P(X > 14 | n = 20, p = 0.60)$  
\ 

To calculate in R:
```{r}
pbinom(q = 14, size = 20, prob = 0.6, lower.tail = F)
```

Not very powerful assuming my estimate of 60% left preference is correct.

## Let's increase sample size

Conclude people prefer left if I observe $X > 59$ "lefts" in 100 trials. Assume people prefer left 60% of the time.  
\ 

Power is $P(X > 59 | n = 100, p = 0.60)$.

```{r}
pbinom(q = 59, size = 100, prob = 0.6, lower.tail = F)
```

Better, but still not close to 0.80. We see increasing sample size increased power.

## Let's increase effect size

Conclude people prefer left if I observe $X > 59$ "lefts" in 100 trials. Assume people prefer left 65% of the time.  
\ 

Power is $P(X > 59 | n = 100, p = 0.65)$.  
\ 

```{r}
pbinom(q = 59, size = 100, prob = 0.65, lower.tail = F)
```

We achieved a high power, assuming we're correct about the probability of left-placement being 65%. We see simply increasing the assumed probability of "left" (or increasing the _effect size_) increased power.


## Type I error

What if I conclude people prefer left when they actually do not? I have made a _Type I error_.  
\ 

Type I error, or $\alpha$, is $P(X > 59 | n = 100, p = 0.5)$.

```{r}
pbinom(q = 59, size = 100, prob = 0.5, lower.tail = F)
```

We usually want Type I error, $\alpha$, to be less than 0.05. In practice it is set to a  fixed value, called the _significance level_, and used in formulas to calculate power.   

## Type II error

What if conclude people have no preference even if they truly prefer left 65% of the time? I have made a _Type II error_.  
\ 

Type II error, or $\beta$,  is $P(X \le 59 | n = 100, p = 0.65)$.

```{r}
pbinom(q = 59, size = 100, prob = 0.65)
```

Type II error is just 1 $-$ Power. Likewise, Power is $1 - \beta$.


## Determining sample size

We usually want to determine a sample size that gives us a desired power.  
\ 

How many people do I need in my experiment to verify people prefer left 65% of the time with 80% power?   
\ 

More is better, but "more" can mean unnecessary time and money. Why recruit 100 people if 80 will do? 

## Estimating sample size 

Assume people prefer left 65% of the time and we reject the notion that there is no preference if we witness more than 60% "lefts" at the end of our experiment. Compare two sample sizes:  
\ 

$P(X > 60 | n = 100, p = 0.65)$ vs. $P(X > 48 | n = 80, p = 0.65)$

```{r}
pbinom(q = 60, size = 100, prob = 0.65, lower.tail = F) 
pbinom(q = 48, size = 80, prob = 0.65, lower.tail = F) 
```

It appears 80 people provide sufficient power (about 80%).


## Visualizing a hypothesis test

```{r echo=FALSE}
p1 <- dbinom(x = 0:100, size = 100, prob = 0.65)
p2 <- dbinom(x = 0:100, size = 100, prob = 0.5)
op <- par(mfrow=c(2,1))
plot(0:100,p2, type="h", main="Null: No preference (50% chance), n = 100", ylab="P", xlab="Number of name tags on left")
abline(v = 60, col="red")
text(80,0.05, "Incorrect Decision (Type I error)")
text(35,0.05, "Correct Decision")
plot(0:100,p1, type="h", main="Alt: Prefer left (65% chance), n = 100", ylab="P", xlab="Number of name tags on left")
abline(v = 60, col="red")
text(85,0.05, "Correct Decision (Power)")
text(40,0.05, "Incorrect Decision (Type II error)")
par(op)
```


## Calculating power and sample size in practice

In the preceding toy example we "manually" calculated power while tweaking sample size and effect size. In practice we use software to do this for us.   
\ 

Power and sample size formulas have been derived for many statistical tests that allows us to...

- calculate **sample size** given power, effect size and significance level
- calculate **power** given sample size, effect size and significance level

The parameters in the formulas are related such that one is determined by the other three. 

## The `pwr` package

Today we'll use three base `R` functions and the `pwr` package.  
\ 

`install.packages("pwr")`   
`library(pwr)`  
\ 

The `pwr` package implements power and sample size analyses as described in _Statistical Power Analysis for the Behavioral Sciences (2nd ed.)_, Cohen (1988).  
\ 

One of the tricks to using the `pwr` package is understanding how it defines _effect size_.

## Effect size

Cohen defines "effect size" as "the degree to which the null hypothesis is false."   
\ 

Example: If our null mean is 100m, and the alternative is 120m, the effect size is 20m.   
\ 

But the functions in the `pwr` package require the effect size to be metric-free (unitless).    
\ 

**This means you need to calculate effect size before using `pwr` functions. Entering the wrong effect size leads to incorrect power and sample size estimates!**   
\ 

Fortunately the `pwr` package provides a few functions for this.

## The `pwr` functions and associated statistical tests (1)

- `pwr.p.test`: one-sample test for proportions (ES=h)    
- `pwr.2p.test`: two-sample test for proportions (ES=h)     
- `pwr.2p2n.test`: two-sample test for proportions, unequal sample sizes (ES=h)    
- `pwr.t.test`: one sample and two sample t tests for means (ES=d)     
- `pwr.t2n.test`: two sample t test for means, unequal sample sizes (ES=d)    

Notice the effect sizes: h and d. We'll define these shortly.

## The `pwr` functions and associated statistical tests (2)

- `pwr.chisq.test`: chi-squared tests; goodness of fit and association (ES=w)
- `pwr.r.test`: correlation test (ES=r)     
- `pwr.anova.test`: test for one-way balanced anova (ES=f)    
- `pwr.f2.test`: test for the general linear model (ES=f2)     

Notice the effect sizes: w, r, f and f2. We'll define these shortly.

## The `ES` functions

Functions to compute effect size:

- `ES.h`: compute effect size h for proportion tests
- `ES.w1`: compute effect size w1 for chi-squared test for goodness of fit
- `ES.w2`: compute effect size w2 for chi-squared test for association
- `cohen.ES`: return conventional effect size (small, medium, large) for all tests available in `pwr`

We will use these functions as needed in the examples that follow.

Other effect sizes (d, f, and f2) must be calculated by hand.
 

## Conventional effect size

Sometimes we don't know the precise effect size we expect or hope to find. In this case we can resort to conventional effect sizes of "small", "medium", or "large".  
\ 

The `cohen.ES` function returns these for us according to the statistical test of interest.   
\ 

For example, a "medium" effect size for a proportion test:
`cohen.ES(test="p", size="medium")`  
\ 

This returns 0.5.

## Base `R` power and sample size functions

Base `R` includes three functions for calculating power and sample size:

- `power.prop.test`: two-sample test for proportions
- `power.t.test`: one-sample and two-sample t tests for means
- `power.anova.test`: one-way analysis of variance tests

These functions do not require calculating a unitless effect size and assume equal sample sizes across groups.


## Leave one out

The `pwr` functions and base `R` functions have `n` and `power` arguments.  
\ 

To calculate `power`, you **leave it out** of the function.   
\ 

To calculate sample size (`n`), you **leave it out** of the function.    
\ 

For example, the following calculates the power of a two-sample t-test with assumed effect size of 0.2, sample of 60 _in each group_, significance level of 0.05 and a (default) two-sided alternative:   
\ 

`pwr.t.test(d=0.2, n=60, sig.level=0.05)`  
\ 

Let's go to R!



## Other Software

### Software
- PASS. http://www.ncss.com/software/pass/ ($395/year or $795 perpetual)
- nQuery. http://www.statsols.com/products/nquery-advisor-nterim/ ($440/year)
- PROC POWER in SAS. Power and sample size analyses for a variety of statistical analyses 
- G*Power. http://www.gpower.hhu.de/en.html (Free)

### R packages
- TrialSize. Functions and examples from the book _Sample Size Calculation in Clinical Research_
- samplesize. Computes sample size for Student's t-test and for the Wilcoxon-Mann-Whitney test for categorical data
- clinfun. Functions for both design and analysis of clinical trials.

## References

Cohen, J. (1988). _Statistical Power Analysis for the Behavioral Sciences (2nd ed.)_. LEA.  
\ 

Hogg, R and Tanis, E. (2006). _Probability and Statistical Inference (7th ed.)_. Pearson.  
\ 

Ryan, T. (2013). _Sample Size Determination and Power_. Wiley.   

## Thanks for coming today!

For help and advice with your statistical analysis: statlab@virginia.edu   
\ 

Sign up for more workshops or see past workshops:   
http://data.library.virginia.edu/statlab/   
\ 

Register for the Research Data Services newsletter to stay up-to-date on StatLab events and resources: http://data.library.virginia.edu/newsletters/    
